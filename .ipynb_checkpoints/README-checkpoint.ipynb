{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"See4C.png\", width=150, ALIGN=\"left\", border=20>\n",
    "<center>\n",
    "<h1>See.4C RTE Challenge Starting Kit</h1>\n",
    "<br>This code was tested with <br>\n",
    "Python 2.7.13 | Anaconda 4.3.1 (https://anaconda.org/)<br>\n",
    "Keras 1.2.1 (https://keras.io/)<br>\n",
    "Tensorflow 0.11.0rc2 (follow Keras instructions)<br>\n",
    "</center>\n",
    "<p><br>\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The SEE.4C CONSORTIUM, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Get Ready!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to find Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "root_dir = '.' # We assume that you are running this example where you originally found it.\n",
    "util_dir = os.path.join(root_dir, 'utilities')\n",
    "code_dir = os.path.join(root_dir, 'sample_code')\n",
    "sys.path.append(util_dir)\n",
    "sys.path.append(code_dir)\n",
    "cache_dir = os.path.join(root_dir, 'cache')\n",
    "from data_io import mkdir\n",
    "mkdir(cache_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a few classes and function in the sample_code directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear_kernels.py', 'prednet.py', 'prednet_baseline.py', 'prednet_utils.py', 'simple_model.py']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for (path, dirs, files) in os.walk(code_dir): print [file for file in files if file.endswith('.py')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to find Sample Data\n",
    "Data are stored in this example like on the See.4C server (where your code submission are evaluated) in two subdirectories \"train\" and \"adapt\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sample_data: 2 files\n",
      "./sample_data/adapt: 69 files\n",
      "./sample_data/train: 1 files\n",
      "./sample_data/train/Xm1: 290 files\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(root_dir, 'sample_data')\n",
    "for (path, dirs, files) in os.walk(data_dir): print \"%s: %d files\" % (path, len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"train\" directory contains sub-directories named \"Xmn\", where \"n\" is a number that can range from 1 to 4 (in the sample_data n=1 or n=2).                                    \n",
    "`In the sample data we provide with the starting kit you get only:\n",
    "    Xm1 = sample data,\n",
    "In the feedback phase, you will get more:\n",
    "    Xm2 = \"public\" data,\n",
    "    Xm1 = \"feedback_train\" data. \n",
    "In the validation phase, you will get yet more:\n",
    "    Xm4 = \"public\" data,\n",
    "    Xm3 = \"feedback_train\" data,\n",
    "    Xm2 = \"feedback_adapt\" data,\n",
    "    Xm1 = \"validation_train\" data.`                    \n",
    "In each directory, video clips are stored in the hdf5 format as Xp.h5, where p is the clip number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DataManager object\n",
    "The DataManager class allows you to painlessly load video clips into an object, as numpy arrays. As RTE data is secret, the spatial information is originally masked. To recover this information, we have implemented the Self Organising Mapping (SOM) in DataManager. This functionality is by default active (DataManager.two_d_map=True) and uses a pre-trained map './utilities/Midx_199_44by44.txt' to map the data to 2D array of shape (horizon, 44, 44). We also provide another pre-trained map './utilities/Midx_199_64by64.txt' which maps data to shape (horizon, 64, 64), this is useful when using PredNet. You can switch maps by changing the parameter DataManager.map_file (see commented examples below). To turn off the 2D mapping and load simply the original data, you can just set the parameter 'two_d_map=False' when initializing the DataManager object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load one statio-temporal sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Manager :: Version = 1\n",
      "Data Manager :: ========= Loading data from sample_data/adapt/X0.h5\n",
      "[+] Success in  0.01 sec\n"
     ]
    }
   ],
   "source": [
    "from data_manager import DataManager \n",
    "cache_file = os.path.join(cache_dir, \"DM.pickle\") #  This will allow faster reload\n",
    "DM = DataManager(data_file = 'sample_data/adapt/X0.h5', verbose=True, cache_file=cache_file, two_d_map=True, map_file='./utilities/Midx_199_44by44.txt')\n",
    "# DM = DataManager(data_file = 'sample_data/adapt/X0.h5', verbose=True, cache_file=cache_file, two_d_map=True, map_file='./utilities/Midx_199_64by64.txt') \n",
    "# DM = DataManager(data_file = 'sample_data/adapt/X0.h5', verbose=True, cache_file=cache_file, two_d_map=False) \n",
    "# set two_d_map=False to load the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also just construct a DM with `DM =  DataManager()`, then call `DM.loadData(data_file = 'xxx')`.\n",
    "\n",
    "DM contains 2 attributes: \n",
    "    - X: ndarray representing an array of feature vectors (frames); frames characterize the power grid state.\n",
    "    - t: ndarray representing the time index (a positive integer)\n",
    "This command just loaded a single sequence of 12 time steps. Original frames have 1916 dimensions, and they are here mapped via SOM to a 2D array of shape (44, 44)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 44, 44)\n",
      "(12, 1)\n"
     ]
    }
   ],
   "source": [
    "print DM.X.shape\n",
    "print DM.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and reload data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can save your DataManager object to a \"pickle\" or \"h5\" file format. The parameter \"frames\" allows you to specify the frames you want to save. For example, save the first 10 frames on pickle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Data Manager :: ========= Saving data to temp/first_10.pickle\n",
      "[+] Success in  0.00 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_io import mkdir\n",
    "mkdir('temp')\n",
    "DM.saveData(data_file='temp/first_10', format='pickle', frames=(0, 10)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to reload your DataManager object that you have saved before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Manager :: ========= Reloading data from temp/first_10.pickle\n",
      "temp/first_10.pickle\n",
      "[+] Success in  0.00 sec\n",
      "(10, 44, 44)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "DM.reloadData(filename=os.path.join('temp', 'first_10.pickle'))\n",
    "print DM.X.shape\n",
    "print DM.t.shape\n",
    "import shutil # Cleanup\n",
    "shutil.rmtree('temp', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a single file is mainly useful if you want perform predictions using a single time series, but you can do more!\n",
    "\n",
    "### Load the whole training dataset\n",
    "For training, you can load the entire training set. Note that this command erases previously loaded data. It may be reloading from a pickle stores in the cache directory (if it exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Manager :: ========= Reading training data from ./sample_data/train\n",
      "Data Manager :: ========= Reloading data from ./cache/DM.pickle\n",
      "[Errno 2] No such file or directory: './cache/DM.pickle'\n",
      "['Xm1']\n",
      "Loading X1.h5\n",
      "Loading X2.h5\n",
      "Loading X3.h5\n",
      "Loading X4.h5\n",
      "Loading X5.h5\n",
      "Loading X6.h5\n",
      "Loading X7.h5\n",
      "Loading X8.h5\n",
      "Loading X9.h5\n",
      "Loading X10.h5\n",
      "Loading X11.h5\n",
      "Loading X12.h5\n",
      "Loading X13.h5\n",
      "Loading X14.h5\n",
      "Loading X15.h5\n",
      "Loading X16.h5\n",
      "Loading X17.h5\n",
      "Loading X18.h5\n",
      "Loading X19.h5\n",
      "Loading X20.h5\n",
      "Loading X21.h5\n",
      "Loading X22.h5\n",
      "Loading X23.h5\n",
      "Loading X24.h5\n",
      "Loading X25.h5\n",
      "Loading X26.h5\n",
      "Loading X27.h5\n",
      "Loading X28.h5\n",
      "Loading X29.h5\n",
      "Loading X30.h5\n",
      "Loading X31.h5\n",
      "Loading X32.h5\n",
      "Loading X33.h5\n",
      "Loading X34.h5\n",
      "Loading X35.h5\n",
      "Loading X36.h5\n",
      "Loading X37.h5\n",
      "Loading X38.h5\n",
      "Loading X39.h5\n",
      "Loading X40.h5\n",
      "Loading X41.h5\n",
      "Loading X42.h5\n",
      "Loading X43.h5\n",
      "Loading X44.h5\n",
      "Loading X45.h5\n",
      "Loading X46.h5\n",
      "Loading X47.h5\n",
      "Loading X48.h5\n",
      "Loading X49.h5\n",
      "Loading X50.h5\n",
      "Loading X51.h5\n",
      "Loading X52.h5\n",
      "Loading X53.h5\n",
      "Loading X54.h5\n",
      "Loading X55.h5\n",
      "Loading X56.h5\n",
      "Loading X57.h5\n",
      "Loading X58.h5\n",
      "Loading X59.h5\n",
      "Loading X60.h5\n",
      "Loading X61.h5\n",
      "Loading X62.h5\n",
      "Loading X63.h5\n",
      "Loading X64.h5\n",
      "Loading X65.h5\n",
      "Loading X66.h5\n",
      "Loading X67.h5\n",
      "Loading X68.h5\n",
      "Loading X69.h5\n",
      "Loading X70.h5\n",
      "Loading X71.h5\n",
      "Loading X72.h5\n",
      "Loading X73.h5\n",
      "Loading X74.h5\n",
      "Loading X75.h5\n",
      "Loading X76.h5\n",
      "Loading X77.h5\n",
      "Loading X78.h5\n",
      "Loading X79.h5\n",
      "Loading X80.h5\n",
      "Loading X81.h5\n",
      "Loading X82.h5\n",
      "Loading X83.h5\n",
      "Loading X84.h5\n",
      "Loading X85.h5\n",
      "Loading X86.h5\n",
      "Loading X87.h5\n",
      "Loading X88.h5\n",
      "Loading X89.h5\n",
      "Loading X90.h5\n",
      "Loading X91.h5\n",
      "Loading X92.h5\n",
      "Loading X93.h5\n",
      "Loading X94.h5\n",
      "Loading X95.h5\n",
      "Loading X96.h5\n",
      "Loading X97.h5\n",
      "Loading X98.h5\n",
      "Loading X99.h5\n",
      "Loading X100.h5\n",
      "Loading X101.h5\n",
      "Loading X102.h5\n",
      "Loading X103.h5\n",
      "Loading X104.h5\n",
      "Loading X105.h5\n",
      "Loading X106.h5\n",
      "Loading X107.h5\n",
      "Loading X108.h5\n",
      "Loading X109.h5\n",
      "Loading X110.h5\n",
      "Loading X111.h5\n",
      "Loading X112.h5\n",
      "Loading X113.h5\n",
      "Loading X114.h5\n",
      "Loading X115.h5\n",
      "Loading X116.h5\n",
      "Loading X117.h5\n",
      "Loading X118.h5\n",
      "Loading X119.h5\n",
      "Loading X120.h5\n",
      "Loading X121.h5\n",
      "Loading X122.h5\n",
      "Loading X123.h5\n",
      "Loading X124.h5\n",
      "Loading X125.h5\n",
      "Loading X126.h5\n",
      "Loading X127.h5\n",
      "Loading X128.h5\n",
      "Loading X129.h5\n",
      "Loading X130.h5\n",
      "Loading X131.h5\n",
      "Loading X132.h5\n",
      "Loading X133.h5\n",
      "Loading X134.h5\n",
      "Loading X135.h5\n",
      "Loading X136.h5\n",
      "Loading X137.h5\n",
      "Loading X138.h5\n",
      "Loading X139.h5\n",
      "Loading X140.h5\n",
      "Loading X141.h5\n",
      "Loading X142.h5\n",
      "Loading X143.h5\n",
      "Loading X144.h5\n",
      "Loading X145.h5\n",
      "Loading X146.h5\n",
      "Loading X147.h5\n",
      "Loading X148.h5\n",
      "Loading X149.h5\n",
      "Loading X150.h5\n",
      "Loading X151.h5\n",
      "Loading X152.h5\n",
      "Loading X153.h5\n",
      "Loading X154.h5\n",
      "Loading X155.h5\n",
      "Loading X156.h5\n",
      "Loading X157.h5\n",
      "Loading X158.h5\n",
      "Loading X159.h5\n",
      "Loading X160.h5\n",
      "Loading X161.h5\n",
      "Loading X162.h5\n",
      "Loading X163.h5\n",
      "Loading X164.h5\n",
      "Loading X165.h5\n",
      "Loading X166.h5\n",
      "Loading X167.h5\n",
      "Loading X168.h5\n",
      "Loading X169.h5\n",
      "Loading X170.h5\n",
      "Loading X171.h5\n",
      "Loading X172.h5\n",
      "Loading X173.h5\n",
      "Loading X174.h5\n",
      "Loading X175.h5\n",
      "Loading X176.h5\n",
      "Loading X177.h5\n",
      "Loading X178.h5\n",
      "Loading X179.h5\n",
      "Loading X180.h5\n",
      "Loading X181.h5\n",
      "Loading X182.h5\n",
      "Loading X183.h5\n",
      "Loading X184.h5\n",
      "Loading X185.h5\n",
      "Loading X186.h5\n",
      "Loading X187.h5\n",
      "Loading X188.h5\n",
      "Loading X189.h5\n",
      "Loading X190.h5\n",
      "Loading X191.h5\n",
      "Loading X192.h5\n",
      "Loading X193.h5\n",
      "Loading X194.h5\n",
      "Loading X195.h5\n",
      "Loading X196.h5\n",
      "Loading X197.h5\n",
      "Loading X198.h5\n",
      "Loading X199.h5\n",
      "Loading X200.h5\n",
      "Loading X201.h5\n",
      "Loading X202.h5\n",
      "Loading X203.h5\n",
      "Loading X204.h5\n",
      "Loading X205.h5\n",
      "Loading X206.h5\n",
      "Loading X207.h5\n",
      "Loading X208.h5\n",
      "Loading X209.h5\n",
      "Loading X210.h5\n",
      "Loading X211.h5\n",
      "Loading X212.h5\n",
      "Loading X213.h5\n",
      "Loading X214.h5\n",
      "Loading X215.h5\n",
      "Loading X216.h5\n",
      "Loading X217.h5\n",
      "Loading X218.h5\n",
      "Loading X219.h5\n",
      "Loading X220.h5\n",
      "Loading X221.h5\n",
      "Loading X222.h5\n",
      "Loading X223.h5\n",
      "Loading X224.h5\n",
      "Loading X225.h5\n",
      "Loading X226.h5\n",
      "Loading X227.h5\n",
      "Loading X228.h5\n",
      "Loading X229.h5\n",
      "Loading X230.h5\n",
      "Loading X231.h5\n",
      "Loading X232.h5\n",
      "Loading X233.h5\n",
      "Loading X234.h5\n",
      "Loading X235.h5\n",
      "Loading X236.h5\n",
      "Loading X237.h5\n",
      "Loading X238.h5\n",
      "Loading X239.h5\n",
      "Loading X240.h5\n",
      "Loading X241.h5\n",
      "Loading X242.h5\n",
      "Loading X243.h5\n",
      "Loading X244.h5\n",
      "Loading X245.h5\n",
      "Loading X246.h5\n",
      "Loading X247.h5\n",
      "Loading X248.h5\n",
      "Loading X249.h5\n",
      "Loading X250.h5\n",
      "Loading X251.h5\n",
      "Loading X252.h5\n",
      "Loading X253.h5\n",
      "Loading X254.h5\n",
      "Loading X255.h5\n",
      "Loading X256.h5\n",
      "Loading X257.h5\n",
      "Loading X258.h5\n",
      "Loading X259.h5\n",
      "Loading X260.h5\n",
      "Loading X261.h5\n",
      "Loading X262.h5\n",
      "Loading X263.h5\n",
      "Loading X264.h5\n",
      "Loading X265.h5\n",
      "Loading X266.h5\n",
      "Loading X267.h5\n",
      "Loading X268.h5\n",
      "Loading X269.h5\n",
      "Loading X270.h5\n",
      "Loading X271.h5\n",
      "Loading X272.h5\n",
      "Loading X273.h5\n",
      "Loading X274.h5\n",
      "Loading X275.h5\n",
      "Loading X276.h5\n",
      "Loading X277.h5\n",
      "Loading X278.h5\n",
      "Loading X279.h5\n",
      "Loading X280.h5\n",
      "Loading X281.h5\n",
      "Loading X282.h5\n",
      "Loading X283.h5\n",
      "Loading X284.h5\n",
      "Loading X285.h5\n",
      "Loading X286.h5\n",
      "Loading X287.h5\n",
      "Loading X288.h5\n",
      "Loading X289.h5\n",
      "Data Manager :: ========= Saving data to ./cache/DM.pickle\n",
      "[+] Success in  5.47 sec\n",
      "[+] Success, loaded 289 videos in 189.60 sec\n",
      "(105049, 44, 44)\n",
      "(105049, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "DM.loadTrainData(train_data_dir)\n",
    "print DM.X.shape\n",
    "print DM.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append more data\n",
    "After loading the training data X, you can append to X some additional data from the \"adapt\" directory. Your preditions program will be expected to make prediction on data from the \"adapt\" directory, which will become available progressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105061, 44, 44)\n",
      "(105061, 1)\n"
     ]
    }
   ],
   "source": [
    "adapt_data_dir = os.path.join(data_dir, 'adapt')\n",
    "DM.appendSamples(data_file=\"X0\", data_dir=adapt_data_dir) # append adapt/X0.h5 to X\n",
    "print DM.X.shape\n",
    "print DM.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Explore the data\n",
    "\n",
    "DataManager object also provides methods to help you visualize the data. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABJCAYAAAAt8N2UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e069350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DM.display(start=0, end=1000, step=100) # display every five frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data contains the time of the sample in unix time (seconds since 1970), which is a convention that allows absolute time (dates with arbitrary accuracy) to be represented as numbers. We have reindexed this absolute time as a sequence of integers starting from 0, which corresponds to 1,246,492,800 seconds since 1970. The interval between 2 time indices is 300 seconds, e.g, a file containing 12 frames has time indices [0, 1, 2, ..., 11], corresponding to a duration of $11*300=3300$ seconds. The files and contiguous sequences have a variable number of frames. The goal is to predict 11 frames in the future.\n",
    "The DataManager allows you to append files from the adapt directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Manager :: ========= Reading training data from ./sample_data/train\n",
      "Data Manager :: ========= Reloading data from ./cache/DM.pickle\n",
      "./cache/DM.pickle\n",
      "[+] Success in 14.06 sec\n",
      "[+] Success, loaded 0 videos in 14.06 sec\n",
      "Appending 69 files from ./sample_data/adapt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x119e8c650>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8nHOORd3nnycc87F3f8DLGsKAql06EwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119e54310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DM.loadTrainData(train_data_dir)\n",
    "from glob import glob as ls\n",
    "fn = len(ls(adapt_data_dir + '/*.h5'))\n",
    "print 'Appending %d files from %s' % (fn, adapt_data_dir)\n",
    "for i in range(fn):\n",
    "    DM.appendSamples(i, data_dir=adapt_data_dir) \n",
    "import matplotlib.pyplot as plt\n",
    "fnum = len(DM.t)\n",
    "plt.plot(DM.t[1:fnum])\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Time index')\n",
    "plt.title(\"Found %d contiguous sequences in the first %d frames\" % (list(DM.t[1:fnum]).count(0), fnum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Train, Adapt, and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to write your code. Use *simple_model.py* as a template. It has three main functions, \"train\", \"adapt\", and \"predict\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from simple_model import Model #persistence\n",
    "from linear_kernels import Model\n",
    "# Model??\n",
    "# Uncomment the previous line if you want to see the code of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Load the entire training set and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Manager :: ========= Reading training data from ./sample_data/train\n",
      "Data Manager :: ========= Reloading data from ./cache/DM.pickle\n",
      "./cache/DM.pickle\n",
      "[+] Success in 12.76 sec\n",
      "[+] Success, loaded 0 videos in 12.76 sec\n",
      "Model :: ========= Training model =========\n",
      "[+] Success in  0.00 sec\n"
     ]
    }
   ],
   "source": [
    "M = Model(verbose=True) # No hyper-parameter here, this model just implements persistence :-)\n",
    "DM.loadTrainData(train_data_dir)\n",
    "M.train(DM.X, DM.t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt\n",
    "Add a few more frames and adapt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model :: ========= Adapting model =========\n",
      "[+] Success in  0.00 sec\n"
     ]
    }
   ],
   "source": [
    "DM.appendSamples(data_file=\"X0\", data_dir=adapt_data_dir)\n",
    "M.adapt(DM.X, DM.t) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Predict the next frame_num frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model :: ========= Making predictions =========\n",
      "OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./sample_code/linear_kernels.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  i, j, k, l)) / (np.linalg.norm([v for v in self.img_history[1:, i, j]]) * np.linalg.norm(self.get_vect(i, j, k, l)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Success in  1.66 sec\n"
     ]
    }
   ],
   "source": [
    "RESULT = DataManager()\n",
    "# RESULT = DataManager(map_file='./utilities/Midx_199_64by64.txt') #if you use the 64by64 map\n",
    "frame_num=11\n",
    "RESULT.X = M.predict(DM.X, num_predicted_frames=frame_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 44, 44)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABJCAYAAAAt8N2UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBbohmEYPYIFumEYRo/w36sOuGqcel+4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115dba3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RESULT.display(start=0, end=frame_num-1, step=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: Compute your Accuracy\n",
    "Prediction accuracy is computed using the RMSE. You can load the next chunk and see whether your predictions are accurate. On the server, when your code is tested, the next chunk is released only when you have made your predictions for the next 8 frames based on previously released data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 19.94\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from libscores import mse\n",
    "DM.appendSamples(data_file=\"X1\", data_dir=adapt_data_dir) # Get the next chunk\n",
    "# solution = DM.X[-frame_num:].ravel() #if you use the original non-mapped data\n",
    "# prediction = RESULT.X.ravel()\n",
    "solution = DM.map_back_to_1d(X_2d=DM.X[-frame_num:]).ravel()\n",
    "prediction = RESULT.map_back_to_1d(X_2d = RESULT.X).ravel()\n",
    "# print solution.shape\n",
    "# print prediction.shape\n",
    "print (\"RMSE = %5.2f\" % np.sqrt(mse(solution, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data organization\n",
    "The expected sequence of query and answer videos will be:\n",
    "<pre>\n",
    "input name : number of frames    output name : number of frames\n",
    "\n",
    "X0.h5 : 101 frames               Y0.h5   :   8 frames\n",
    "X1.h5 : 8 frames                 Y1.h5   :   8 frames\n",
    "X2.h5 : 8 frames                 Y2.h5   :   8 frames\n",
    "X3.h5 : 109 frames               Y3.h5   :   8 frames\n",
    "X4.h5 : 8 frames                 Y4.h5   :   8 frames\n",
    "X5.h5 : 8 frames                 Y5.h5   :   8 frames\n",
    "X6.h5 : 109 frames               Y6.h5   :   8 frames     \n",
    "...\n",
    "X599.h5 \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on the entire \"adapt\" series\n",
    "This program tests your data and computes the RMSE on sample data.\n",
    "Point data_dir to the public data if you want a larger sample. It calls predictSpatioTemporal.py, so this is a full test. Scroll down to get your RMSE on sample data. WARNING: This can take long, you may want to comment this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************Cannot find prediction files in ./results*****************************\r\n",
      "*****************************Now computing predictions using predictSpatioTemporal (persistance model)*****************************\r\n",
      "\r\n",
      "====> STEP: 0\r\n",
      "Using input_dir: sample_data\r\n",
      "Using output_dir: ./results\r\n",
      "Using code_dir: ./\r\n",
      "Using cache_dir: ./cache\r\n",
      "************************************************\r\n",
      "******** Processing data chunk number 0 ********\r\n",
      "************************************************\r\n",
      "Data Manager :: Version = 1\r\n",
      "Data Manager :: Version = 1\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng/utilities/data_manager.py\", line 423, in two_d_mapping\r\n",
      "    Midx = np.loadtxt(self.map_file)\r\n",
      "  File \"/Users/lishengsun/anaconda/lib/python2.7/site-packages/numpy/lib/npyio.py\", line 803, in loadtxt\r\n",
      "    fh = iter(open(fname, 'U'))\r\n",
      "IOError: [Errno 2] No such file or directory: './utilities/Midx_199_44by44.txt'\r\n",
      "\r\n",
      "Error \r\n",
      " Data has not been transformed to 2D array.\r\n",
      "Model :: ========= Adapting model =========\r\n",
      "[+] Success in  0.00 sec\r\n",
      "Model :: ========= Making predictions =========\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"utilities/score.py\", line 122, in <module>\r\n",
      "    predict(step_num, data_dir, result_dir, code_dir, cache_dir=cache_dir, num_predicted_frames=frame_num)\r\n",
      "  File \"./predictSpatioTemporal.py\", line 196, in predictSpatioTemporal\r\n",
      "    Dout.X = M.predict(Din.X, num_predicted_frames=num_predicted_frames)\r\n",
      "  File \"./sample_code/linear_kernels.py\", line 135, in predict\r\n",
      "    self.img_history = self.scale(self.img_history)\r\n",
      "  File \"./sample_code/linear_kernels.py\", line 40, in scale\r\n",
      "    data[:, i, j].reshape((-1, 1))).reshape((-1))\r\n",
      "IndexError: index 1 is out of bounds for axis 2 with size 1\r\n"
     ]
    }
   ],
   "source": [
    "# !python $util_dir/score.py $data_dir $out_dir $root_dir #if this doesn't work, uncomment and try the second command \n",
    "!python 'utilities/score.py' 'sample_data' 'results' './' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Prepare your Submission\n",
    "\n",
    "## Unit testing\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code/</code> directory, then run this test to make sure everything works fine. The first argument is the \"step\" number, try at least two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = os.path.join(root_dir, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====> STEP: 0\n",
      "Using input_dir: ./sample_data\n",
      "Using output_dir: /Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng/results\n",
      "Using code_dir: .\n",
      "Using cache_dir: .\n",
      "{'max_samples': inf, 'verbose': False, 'datatype': 'unknown', 'two_d_map': True, 'use_pickle': False, 'cache_file': '', 'version': '1', 't': array([], dtype=float64), 'X': array([], dtype=float64), 'map_file': './utilities/Midx_199_44by44.txt'}\n",
      "(['class DataManager:\\n', '    \\n', \"    ''' This class aims at loading, saving, and displaying data.\\n\", '    \\n', '    Data members:\\n', '    datatype = one of \"public\", \"feedback\", or \"validate\"\\n', '    X = data matrix, samples in lines (time index increasing with line), features in columns.\\n', '    t = time index. The time index may show ruptures e.g. 0, 1, 2, 3, 0, 1, 2, 3; indicating cuts.\\n', '     \\n', '    Methods defined:\\n', '    __init__ (...)\\n', '        x.__init__([(feature, value)]) -> void\\t\\t\\n', '        Initialize the data members with the tuples (feature, value) given as argument. An unlimited number of tuples can be passed as argument.\\n', '        If input_dir is given, calls loadTrainData.\\n', '        Parameters:\\n', '        two_d_map: bool. Maps 1d array data to 2d using a pre-trained SOM (Self Organizing Map) map when True (default).\\n', \"        map_file: the SOM map used when two_d_map. default ='./utilities/Midx_199_44by44.txt'\\n\", '        \\n', '    loadTrainData (...)\\n', '        x.loadData (input_dir, max_samples=float(\\'inf\\'), verbose=\"True\") -> success\\t\\t\\n', '        Load all the training samples found in directory input_dir/train. \\n', '        Ignores the samples in input_dir/adapt, if any.\\n', '        input_dir/train may contain multiple subdirectories, Xmn/.\\n', '        The data must be read from all of them, it order of DECREASING values of n.\\n', '        The directories contains files Xn.h5, which must be read in order if INCREASING n values.\\n', '        If data are already loaded, this function overwrites X, unless append=\"True\".\\n', '        For speed reasons, stops after max_samples samples (frames) have been read.\\n', '        Returns success=\"True/False\".\\n', '        =============================\\n', '        loadTrainData() returns a ndarray X and a time index array t\\n', '            X.shape(total_num_of_frames=101*125frames/videos, 32,32)\\n', '            t = array([0, ...., 124, 0, ...., 124,...]), t.shape=(total_num_of_frames,)\\n', '\\t\\t\\n', '    appendSamples (...)\\n', '        x.appendSamples (chunk_num, input_dir, verbose=\"True\") -> success\\t\\t\\n', '        Append to X all the samples found in directory input_dir/adapt/Xn.h5, where n=chunk_num.\\n', '        Returns success=\"True/False\".        \\n', '        \\n', '    getInfo (...)\\n', '        x.getInfo () -> string\\t\\n', '        Pretty prints information about the object.\\n', '\\n', '    saveData() \\n', '        save read data (array X, T) to pickle or h5 file\\t\\t\\n', \"    '''\\n\", '\\t\\n', '    def __init__(self, datatype=\"unknown\", data_file=\"\", verbose=False, max_samples=float(\\'inf\\'), cache_file=\"\", two_d_map=True, map_file=\\'./utilities/Midx_199_44by44.txt\\'):\\n', \"        '''Constructor'''\\n\", '        self.version = \"1\"\\n', '        self.datatype = datatype \\n', '        self.verbose = verbose\\n', '        self.max_samples=max_samples\\n', '        self.two_d_map = two_d_map\\n', '        self.map_file = map_file\\n', '        self.cache_file=cache_file # To save/reload data in binary format (only if not empty)\\n', '        if not cache_file: \\n', '            self.use_pickle = False\\n', '        else:\\n', '            self.use_pickle = True\\n', '        self.X = np.array([])\\n', '        self.t = np.array([])\\n', '        vprint(self.verbose, \"Data Manager :: Version = \" + self.version)\\n', '        if data_file:\\n', '            self.loadData(data_file)\\n', '\\n', '           \\n', '    def __repr__(self):\\n', '        return \"DataManager :\\\\n\\\\t\" + str(self.X.__repr__) + \"\\\\n\\\\t\" + str(self.t.__repr__)\\n', '\\n', '    def __str__(self):\\n', '        val = \"DataManager :\\\\n\" + self.getInfo\\n', '        return val\\n', '  \\n', '    def getInfo(self):\\n', \"        '''A nice string with information about the data.'''       \\n\", '        val = \"\"\\n', '        return val\\n', '        \\n', '    def loadTrainData(self, data_dir=\"\", max_samples=float(\\'inf\\')):\\n', \"        ''' Get the data from hdf5 files.'''\\n\", '        success = True\\n', '        data_reloaded = False\\n', '        vprint(self.verbose, \"Data Manager :: ========= Reading training data from \" + data_dir)\\n', '        start = time.time()\\n', '        vid=0\\n', '        if self.use_pickle and self.reloadData(self.cache_file):\\n', '            # Try to reload the file from a pickle\\n', '            data_reloaded = True # Turn \"success\" to false if there is a problem.\\n', '        else:\\n', '            # Load the data into X and t.\\n', '            dir_list = []\\n', '            for dir in os.listdir(data_dir):\\n', '                if os.path.isdir(os.path.join(data_dir, dir)):\\n', '                    dir_list.append(dir)\\n', '            # sort dir in decreasing order of n for n in Xmn        \\n', \"            dir_list = sorted(dir_list, key=lambda i: i.split('m')[-1], reverse=True)\\n\", '            vprint(self.verbose, dir_list)\\n', '            self.X=np.array([]) # Re-initialize from scratch\\n', '            self.t=np.array([])\\n', '            for dir in dir_list:\\n', \"                for data_file in sorted([h5file for h5file in os.listdir(os.path.join(data_dir, dir)) if h5file.endswith('h5')],key=lambda i:int(i.split('.')[0].split('X')[-1])):\\n\", '                    vprint(self.verbose, \"Loading %s\"%data_file)\\n', '                    self.appendSamples(data_file, os.path.join(data_dir, dir), verbose=False)\\n', '                    vid=vid+1\\n', '                   \\n', '        if self.use_pickle and not data_reloaded:\\n', '            # Save data as a pickle for \"faster\" later reload\\n', \"            self.saveData(self.cache_file, format='pickle')\\n\", '            \\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose, \"[+] Success, loaded %d videos in %5.2f sec\" % (vid, end - start))\\n', '        return success\\n', '\\t\\n', '\\n', '    def appendSamples(self, data_file, data_dir=\"\", verbose=False):\\n', \"        ''' After loading training samples, get additional data from the adapt directory.\\n\", \"        data_file: Number n of the 'chunk' or 'step' (appearing in the file name)\\n\", '        Alternatively, the full file name Xn can be supplied as a string instead of the chunk number.\\n', \"        '''\\n\", '        success = True\\n', '        start = time.time()\\n', '        # Append new data to X and t.\\n', '        if isinstance(data_file, int):\\n', '            data_file = \"X\" + str(data_file)\\n', '        vprint(self.verbose and verbose, \"Data Manager :: ========= Appending samples \" + data_dir +  data_file)\\n', '        X_add, t_add = self.getOneSample(data_file, data_dir)\\n', '        #if t_add[0]==0: print \"New sequence\"\\n', '        #print \"%s %d %d %d\" % (data_file, np.min(t_add), np.max(t_add), len(t_add))\\n', '            \\n', '        if len(self.X)==0:\\n', '            self.X = X_add\\n', '            self.t = t_add\\n', '        else:\\n', '            self.X = np.vstack((self.X, X_add))\\n', '\\n', '            if t_add[0][0] == 0:\\n', '                t_add = np.array([t+1+self.t[-1][0] for t in t_add]).reshape(t_add.shape)\\n', '            self.t = np.vstack((self.t, t_add))\\n', '\\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose and verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose and verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '        \\n', '    def loadData(self, data_file, data_dir=\"\"):\\n', \"        ''' Erase previous data and load data from a give data file.\\n\", \"        data_file: Number n of the 'chunk' or 'step' (appearing in the file name)\\n\", '        Alternatively, the full file name Xn can be supplied as a string instead of the chunk number.\\n', \"        '''\\n\", '        success = True\\n', '        start = time.time() \\n', '        if isinstance(data_file, int):\\n', '            data_file = \"X\" + str(data_file)\\n', '        vprint(self.verbose, \"Data Manager :: ========= Loading data from \" + data_file)          \\n', '        self.X, self.t = self.getOneSample(data_file, data_dir)\\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        \\n', '        return success\\n', '        \\n', '    def getOneSample(self, data_file, data_dir=\"\"):\\n', \"        ''' Return one video read from hdf5 format: \\n\", '        Parameters: \\n', '            data_file: file name (no extention)\\n', '            data_dir: data path\\n', \"        '''\\n\", '        try:\\n', '            # try:\\n', \"            #     f_0 = h5py.File('./sample_data/train/Xm1/X1.h5','r')#This is the first file and will give the first timestamp t0\\n\", '            #     print data_dir\\n', \"            #     print os.path.join(data_dir,'train/Xm1/X1.h5')\\n\", \"            #     # f_0 = h5py.File(os.path.join(data_dir,'train/Xm1/X1.h5'),'r')\\n\", \"            #     t_0 = np.array(f_0['X']['value']['t']['value'][:])[0][0]\\n\", '            # except: # use the first file in /train/Xm1 as starting file\\n', \"            #     f_0 = sorted(os.listdir('./sample_data/train/Xm1/'), key=lambda f:int(f.split('.')[0].split('X')[-1]))[0]\\n\", \"            #     t_0 = np.array(f_0['X']['value']['t']['value'][:])[0][0]\\n\", '            #     vprint (self.verbose, \"Cannot load train/Xm1/X1.h5 to initialize time indexing. Instead use the first file in train/Xm1/.\")\\n', '            \\n', '            t_0 = 1246492800.0\\n', '            \\n', \"            if not data_file.endswith('.h5'):\\n\", \"                data_file = data_file + '.h5'\\n\", \"            f = h5py.File(os.path.join(data_dir, data_file),'r')\\n\", '            try:\\n', \"                X = np.array(f['X']['value']['X']['value'][:])\\n\", '                \\n', '                ### corrected by Lisheng ####\\n', \"                # if 't' in f: \\n\", \"                #     X = np.array(f['t']['value']['t']['value'][:])\\n\", \"                if 't' in f['X']['value']:\\n\", \"                    t_absolute = np.array(f['X']['value']['t']['value'][:])\\n\", '                    # print t_absolute[:,0].tolist()\\n', '                    # print t_0\\n', '                    # t = [int(float(t_abs-t0)/300) for t_abs in t_absolute.tolist()]\\n', '                    t = [(t_abs-t_0)/300 for t_abs in t_absolute[:,0].tolist()]\\n', '                    # print t\\n', '                    t = np.array(t).reshape(t_absolute.shape)\\n', '\\n', '                ### corrected by Lisheng ####\\n', '                else:\\n', '                    t = np.array(range(X.shape[0]))\\n', '                \\n', \"            except: # Lisheng's simpler format\\n\", '                try:\\n', \"                    X = np.array(f['X'][:])\\n\", \"                    if 't' in f: \\n\", \"                        t = np.array(f['t'][:])   \\n\", '                    else:\\n', '                        t = np.array(range(X.shape[0])) \\n', '                except Exception:\\n', '                    vprint(self.verbose, traceback.format_exc())\\n', '                    X = np.array([])\\n', '                    t = np.array([])  \\n', '                \\n', '            if len(t)==0 or len(t)!=len(X):\\n', '                t = np.array(range(X.shape[0])) \\n', '            if len(X.shape) > 3: # turn to gray levels\\n', '                X = X[:,:,:,0]\\n', '            if self.two_d_map:\\n', '                # X_1d = np.hstack((X,t))\\n', '                # print X_1d.shape\\n', \"                # vprint (self.verbose, 'Mapping X to 2D')\\n\", '                X = self.two_d_mapping(X)\\n', '        except Exception:\\n', '            print(traceback.format_exc())\\n', '\\n', '\\n', '        return (X, t)\\n', '        \\n', '    def saveData(self, data_file, data_dir=\"\", frames=[], format=\\'pickle\\', map_to_1d=True, map_to_1d_when_starts_with=\\'Y\\'):\\n', \"        ''' Save data in picke / h5 format.        Parameters: \\n\", '            data_file: save data under this filename (no extention)\\n', '            data_dir: where to save data\\n', '            frames: specify which lines in the video matrix to be saved,  \\n', '            e.g. frames=(start_frame, end_frame)=(10,15)\\n', '                    default = entire video matrix\\n', \"            format: 'pickle' or 'h5', default = 'pickle'\\n\", \"            map_to_1d: bool. True (by default): map the predictions back to 1d when they are saved with a filename starting with the value of parameter 'map_to_1d_when_starts_with'; False: save data as it is.\\n\", '            map_to_1d_when_starts_with: str. Indicates the starting part of filename which will get mapped to 1d when map_to_1d=True\\n', \"        '''\\n\", '        if not data_file.endswith(format):\\n', \"            data_file = data_file + '.' + format\\n\", '        success = True\\n', '        if data_file.startswith(map_to_1d_when_starts_with) and map_to_1d:\\n', '            two_d_map = False\\n', '            self.X = self.map_back_to_1d(self.X)\\n', '        try:\\n', '            filename = os.path.join(data_dir, data_file)\\n', '            vprint(self.verbose, \"Data Manager :: ========= Saving data to \" + filename)\\n', '\\n', '            start = time.time()\\n', '            # Write some code to save the data\\n', '            if frames: \\n', \"                if format=='h5': \\n\", \"                    with h5py.File(filename, 'w') as f:\\n\", \"                        f.create_dataset(name='X', shape=self.X[frames[0]:frames[1]].shape, \\\\\\n\", '                            data=self.X[frames[0]:frames[1]])\\n', \"                        f.create_dataset(name='t', shape=self.t[frames[0]:frames[1]].shape, \\\\\\n\", '                            data=self.t[frames[0]:frames[1]])\\n', '                else: \\n', \"                    with open(filename, 'wb') as f:\\n\", \"                        dict_to_save = {key:self.__dict__[key] for key in self.__dict__.keys() if not key in ['X', 't']}\\n\", \"                        dict_to_save['X'] = self.X[frames[0]:frames[1]]\\n\", \"                        dict_to_save['t'] = self.t[frames[0]:frames[1]]\\n\", '                        pickle.dump(dict_to_save, f, 2)\\n', '            else: #save the entire matrix\\n', \"                if format=='h5':\\n\", \"                    with h5py.File(filename, 'w') as f:\\n\", \"                        f.create_dataset(name='X', shape=self.__dict__['X'].shape, data=self.__dict__['X'])\\n\", \"                        f.create_dataset(name='t', shape=self.__dict__['t'].shape, data=self.__dict__['t'])\\n\", '                else: \\n', \"                    with open(filename, 'wb') as f:\\n\", '                        pickle.dump(self.__dict__, f, 2) \\n', '        except Exception as e: \\n', '            vprint (self.verbose, e)\\n', '            success = False\\n', '        end = time.time()\\n', '        vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '\\n', '\\n', '    def reloadData(self, filename=\"\", data_dir=\"\"):\\n', \"        ''' Reload data in pickle format.'''\\n\", '        success = True\\n', '        vprint(self.verbose, \"Data Manager :: ========= Reloading data from \" + filename)\\n', '        start = time.time()\\n', '        # Write some code to reload the data\\n', '        temp =[]\\n', '        try:\\n', \"            if filename.endswith('h5'): \\n\", \"                with h5py.File(os.path.join(data_dir, filename), 'r') as f:\\n\", \"                    self.X = f['X'][:]\\n\", \"                    self.t = f['t'][:]\\n\", \"            elif filename.endswith('pickle'):\\n\", \"                with open(os.path.join(data_dir, filename), 'rb') as f:\\n\", '                    temp = pickle.load(f)\\n', \"                    self.X = temp['X']\\n\", \"                    self.t = temp['t']\\n\", '                    vprint(self.verbose, filename)\\n', '            else:\\n', '                success = False\\n', '                vprint(self.verbose, \"[-] No such file extension.\" + filename)            \\n', '        except Exception as e: \\n', '            vprint (self.verbose, e)\\n', '            success = False \\n', '        end = time.time()\\n', '        if success:\\n', '            vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '\\n', '    def browse(self):\\n', \"        ''' Open a data browser to browse through the data.'''        \\n\", '\\n', '    def play_video(self):\\n', \"        '''play video in python:\\n\", '        http://stackoverflow.com/questions/21313542/how-to-open-a-mp4-file-with-python\\n', \"        '''\\n\", '\\n', '    def motion_history_image(self, start=0, end=10, step=1, tau=10, d=0):\\n', '        \"\"\"\\n', '        start and end and the first and last frame. step is the stride.\\n', '        tau = 50 means we consider only motions taken within 50 frames.\\n', '        d = difference threshold: \\n', \"        if the difference between 2 images < d at a point (x,y), it's considered a motionless point at t\\n\", '        \"\"\"\\n', '        import matplotlib.pyplot as plt\\n', '        # get video frames \\n', '        nmax = len(self.X)\\n', '        if end>nmax: end=nmax\\n', '        if end<start: end=start\\n', '        frame_index_to_display = range(start, end+1, step)\\n', '        frame_list = self.X[frame_index_to_display]\\n', '        # compute difference images\\n', '        difference_images = np.asarray([frame_list[t+1] - frame_list[t] for t in range(len(frame_list)-1)])\\n', '        tmax,xmax,ymax = difference_images.shape\\n', '        # initialize the motion history image\\n', '        MHI = np.zeros((xmax, ymax))\\n', '        #loop over time\\n', '        for t in range(tmax):        \\n', '            #loop each position\\n', '            for x in range(xmax):\\n', '                for y in range(ymax):\\n', '                    if difference_images[t,x,y] > d: # if moving now\\n', '                        # pixel value = max value = tau\\n', '                        MHI[x,y] = tau \\n', '                    else: # if motionless now\\n', '                        # pixel value decays by 1\\n', '                        MHI[x,y] = max(0, MHI[x,y]-1)         \\n', '        plt.imshow(MHI)\\n', '        plt.colorbar()\\n', '        plt.show()\\n', '        return MHI\\n', '        \\n', '\\n', '    def display(self, start=0, end=0, step=1):\\n', \"        ''' Display frames graphically in a nice way.\\n\", '            start and end and the first and last frame. step is the stride.\\n', \"            self.X is a list of array, each array with shape (32, 32).'''\\n\", '        import matplotlib.pyplot as plt\\n', '        fig = plt.figure()\\n', '        plot_i=1\\n', '        nmax = len(self.X)\\n', '        if end>nmax: end=nmax\\n', '        if end<start: end=start\\n', '        frame_index_to_display = range(start, end+1, step)\\n', '        fnum = len(frame_index_to_display)\\n', '        for i in range(fnum):\\n', '            sf = fig.add_subplot(1, fnum, i+1)\\n', \"            sf.imshow(self.X[frame_index_to_display[i]], cmap='gray', interpolation='None')\\n\", '            plot_i += 1\\n', \"            sf.axis('off')\\n\", '            sf.set_title(str(frame_index_to_display[i]))\\n', '        plt.show()\\n', '\\n', '\\n', '    def two_d_mapping(self, X_1d):\\n', '        \"\"\"\\n', '        map 1-d array to a 2-d space with Self Organizing Maps technique. The map used here is defined by self.map_file\\n', '        \"\"\"\\n', '        try:\\n', '            Midx = np.loadtxt(self.map_file)\\n', '            T = X_1d.shape[0]\\n', '            n = Midx.shape[0] #or[1], Midx is square\\n', '            X_2d = np.empty((T,n,n))\\n', '            for i in range(n):\\n', '                for j in range(n):\\n', '                    X_2d[:,i,j] = X_1d[:, int(Midx[i,j])].reshape((T,))\\n', '            return X_2d\\n', '\\n', '        except Exception:\\n', '            vprint(self.verbose, traceback.format_exc())\\n', '            vprint (self.verbose, \"Error \\\\n Data has not been transformed to 2D array.\") \\n', '            return X_1d\\n', '             # retrain the map\\n', '\\n', '    def map_back_to_1d(self, X_2d):\\n', '        \"\"\"\\n', '        map 2-d array back to 1-d using the same maps for 1-d to 2-d (defined by self.map_file). This is useful when saving predictions\\n', '        for the reason of scoring.\\n', '\\n', '        \"\"\"\\n', '        try:\\n', '            Midx = np.loadtxt(self.map_file)\\n', '            try:\\n', \"                original_Xshape = np.array(h5py.File('./sample_data/train/Xm1/X1.h5','r')['X']['value']['X']['value'][:]).shape\\n\", '            except:\\n', '                vprint (self.verbose, \"Error: Cannot load ./sample_data/train/Xm1/X1.h5.\\\\n Use the default value (1916, 1) for 1d array\") \\n', '                original_Xshape = (12, 1916, 1)\\n', '            # print original_Xshape\\n', '            # print X_2d.shape\\n', '            T, n, _ = X_2d.shape\\n', '            X_1d = np.empty((T, original_Xshape[1], original_Xshape[2]))\\n', '            T,m,_ = X_1d.shape\\n', '            \\n', '            where = 0\\n', '            while where < m:\\n', '                for i in range(n):\\n', '                    for j in range(n):\\n', '                        if int(Midx[i,j]) == where:\\n', '                            X_1d[:, where]=X_2d[:,i,j].reshape(X_1d[:, where].shape)\\n', '                where += 1\\n', '            return X_1d\\n', '            \\n', '\\n', '        except Exception:\\n', '            vprint(self.verbose, traceback.format_exc())\\n', '            vprint (self.verbose, \"Error \\\\n Data has not been transformed back to 1D array.\") \\n', '            return X_2d\\n'], 32)\n",
      "./utilities/data_manager.pyc\n",
      "/Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng\n",
      "************************************************\n",
      "******** Processing data chunk number 0 ********\n",
      "************************************************\n",
      "Data Manager :: Version = 1\n",
      "Data Manager :: Version = 1\n",
      "Version = Persitent\n",
      "Model :: ========= Adapting model =========\n",
      "[+] Success, model adapted in  0.00 sec\n",
      "Model :: ========= Making predictions =========\n",
      "[+] Success, predictions made in  0.00 sec\n",
      "Data Manager :: ========= Saving data to /Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng/results/Y0.h5\n",
      "[+] Success in  0.00 sec\n",
      "[+] Done\n",
      "[+] Time spent  1.96 sec ::  Time budget 600.00 sec\n",
      "\n",
      "====> STEP: 1\n",
      "Using input_dir: ./sample_data\n",
      "Using output_dir: /Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng/results\n",
      "Using code_dir: .\n",
      "Using cache_dir: .\n",
      "{'max_samples': inf, 'verbose': False, 'datatype': 'unknown', 'two_d_map': True, 'use_pickle': False, 'cache_file': '', 'version': '1', 't': array([], dtype=float64), 'X': array([], dtype=float64), 'map_file': './utilities/Midx_199_44by44.txt'}\n",
      "(['class DataManager:\\n', '    \\n', \"    ''' This class aims at loading, saving, and displaying data.\\n\", '    \\n', '    Data members:\\n', '    datatype = one of \"public\", \"feedback\", or \"validate\"\\n', '    X = data matrix, samples in lines (time index increasing with line), features in columns.\\n', '    t = time index. The time index may show ruptures e.g. 0, 1, 2, 3, 0, 1, 2, 3; indicating cuts.\\n', '     \\n', '    Methods defined:\\n', '    __init__ (...)\\n', '        x.__init__([(feature, value)]) -> void\\t\\t\\n', '        Initialize the data members with the tuples (feature, value) given as argument. An unlimited number of tuples can be passed as argument.\\n', '        If input_dir is given, calls loadTrainData.\\n', '        Parameters:\\n', '        two_d_map: bool. Maps 1d array data to 2d using a pre-trained SOM (Self Organizing Map) map when True (default).\\n', \"        map_file: the SOM map used when two_d_map. default ='./utilities/Midx_199_44by44.txt'\\n\", '        \\n', '    loadTrainData (...)\\n', '        x.loadData (input_dir, max_samples=float(\\'inf\\'), verbose=\"True\") -> success\\t\\t\\n', '        Load all the training samples found in directory input_dir/train. \\n', '        Ignores the samples in input_dir/adapt, if any.\\n', '        input_dir/train may contain multiple subdirectories, Xmn/.\\n', '        The data must be read from all of them, it order of DECREASING values of n.\\n', '        The directories contains files Xn.h5, which must be read in order if INCREASING n values.\\n', '        If data are already loaded, this function overwrites X, unless append=\"True\".\\n', '        For speed reasons, stops after max_samples samples (frames) have been read.\\n', '        Returns success=\"True/False\".\\n', '        =============================\\n', '        loadTrainData() returns a ndarray X and a time index array t\\n', '            X.shape(total_num_of_frames=101*125frames/videos, 32,32)\\n', '            t = array([0, ...., 124, 0, ...., 124,...]), t.shape=(total_num_of_frames,)\\n', '\\t\\t\\n', '    appendSamples (...)\\n', '        x.appendSamples (chunk_num, input_dir, verbose=\"True\") -> success\\t\\t\\n', '        Append to X all the samples found in directory input_dir/adapt/Xn.h5, where n=chunk_num.\\n', '        Returns success=\"True/False\".        \\n', '        \\n', '    getInfo (...)\\n', '        x.getInfo () -> string\\t\\n', '        Pretty prints information about the object.\\n', '\\n', '    saveData() \\n', '        save read data (array X, T) to pickle or h5 file\\t\\t\\n', \"    '''\\n\", '\\t\\n', '    def __init__(self, datatype=\"unknown\", data_file=\"\", verbose=False, max_samples=float(\\'inf\\'), cache_file=\"\", two_d_map=True, map_file=\\'./utilities/Midx_199_44by44.txt\\'):\\n', \"        '''Constructor'''\\n\", '        self.version = \"1\"\\n', '        self.datatype = datatype \\n', '        self.verbose = verbose\\n', '        self.max_samples=max_samples\\n', '        self.two_d_map = two_d_map\\n', '        self.map_file = map_file\\n', '        self.cache_file=cache_file # To save/reload data in binary format (only if not empty)\\n', '        if not cache_file: \\n', '            self.use_pickle = False\\n', '        else:\\n', '            self.use_pickle = True\\n', '        self.X = np.array([])\\n', '        self.t = np.array([])\\n', '        vprint(self.verbose, \"Data Manager :: Version = \" + self.version)\\n', '        if data_file:\\n', '            self.loadData(data_file)\\n', '\\n', '           \\n', '    def __repr__(self):\\n', '        return \"DataManager :\\\\n\\\\t\" + str(self.X.__repr__) + \"\\\\n\\\\t\" + str(self.t.__repr__)\\n', '\\n', '    def __str__(self):\\n', '        val = \"DataManager :\\\\n\" + self.getInfo\\n', '        return val\\n', '  \\n', '    def getInfo(self):\\n', \"        '''A nice string with information about the data.'''       \\n\", '        val = \"\"\\n', '        return val\\n', '        \\n', '    def loadTrainData(self, data_dir=\"\", max_samples=float(\\'inf\\')):\\n', \"        ''' Get the data from hdf5 files.'''\\n\", '        success = True\\n', '        data_reloaded = False\\n', '        vprint(self.verbose, \"Data Manager :: ========= Reading training data from \" + data_dir)\\n', '        start = time.time()\\n', '        vid=0\\n', '        if self.use_pickle and self.reloadData(self.cache_file):\\n', '            # Try to reload the file from a pickle\\n', '            data_reloaded = True # Turn \"success\" to false if there is a problem.\\n', '        else:\\n', '            # Load the data into X and t.\\n', '            dir_list = []\\n', '            for dir in os.listdir(data_dir):\\n', '                if os.path.isdir(os.path.join(data_dir, dir)):\\n', '                    dir_list.append(dir)\\n', '            # sort dir in decreasing order of n for n in Xmn        \\n', \"            dir_list = sorted(dir_list, key=lambda i: i.split('m')[-1], reverse=True)\\n\", '            vprint(self.verbose, dir_list)\\n', '            self.X=np.array([]) # Re-initialize from scratch\\n', '            self.t=np.array([])\\n', '            for dir in dir_list:\\n', \"                for data_file in sorted([h5file for h5file in os.listdir(os.path.join(data_dir, dir)) if h5file.endswith('h5')],key=lambda i:int(i.split('.')[0].split('X')[-1])):\\n\", '                    vprint(self.verbose, \"Loading %s\"%data_file)\\n', '                    self.appendSamples(data_file, os.path.join(data_dir, dir), verbose=False)\\n', '                    vid=vid+1\\n', '                   \\n', '        if self.use_pickle and not data_reloaded:\\n', '            # Save data as a pickle for \"faster\" later reload\\n', \"            self.saveData(self.cache_file, format='pickle')\\n\", '            \\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose, \"[+] Success, loaded %d videos in %5.2f sec\" % (vid, end - start))\\n', '        return success\\n', '\\t\\n', '\\n', '    def appendSamples(self, data_file, data_dir=\"\", verbose=False):\\n', \"        ''' After loading training samples, get additional data from the adapt directory.\\n\", \"        data_file: Number n of the 'chunk' or 'step' (appearing in the file name)\\n\", '        Alternatively, the full file name Xn can be supplied as a string instead of the chunk number.\\n', \"        '''\\n\", '        success = True\\n', '        start = time.time()\\n', '        # Append new data to X and t.\\n', '        if isinstance(data_file, int):\\n', '            data_file = \"X\" + str(data_file)\\n', '        vprint(self.verbose and verbose, \"Data Manager :: ========= Appending samples \" + data_dir +  data_file)\\n', '        X_add, t_add = self.getOneSample(data_file, data_dir)\\n', '        #if t_add[0]==0: print \"New sequence\"\\n', '        #print \"%s %d %d %d\" % (data_file, np.min(t_add), np.max(t_add), len(t_add))\\n', '            \\n', '        if len(self.X)==0:\\n', '            self.X = X_add\\n', '            self.t = t_add\\n', '        else:\\n', '            self.X = np.vstack((self.X, X_add))\\n', '\\n', '            if t_add[0][0] == 0:\\n', '                t_add = np.array([t+1+self.t[-1][0] for t in t_add]).reshape(t_add.shape)\\n', '            self.t = np.vstack((self.t, t_add))\\n', '\\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose and verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose and verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '        \\n', '    def loadData(self, data_file, data_dir=\"\"):\\n', \"        ''' Erase previous data and load data from a give data file.\\n\", \"        data_file: Number n of the 'chunk' or 'step' (appearing in the file name)\\n\", '        Alternatively, the full file name Xn can be supplied as a string instead of the chunk number.\\n', \"        '''\\n\", '        success = True\\n', '        start = time.time() \\n', '        if isinstance(data_file, int):\\n', '            data_file = \"X\" + str(data_file)\\n', '        vprint(self.verbose, \"Data Manager :: ========= Loading data from \" + data_file)          \\n', '        self.X, self.t = self.getOneSample(data_file, data_dir)\\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        \\n', '        return success\\n', '        \\n', '    def getOneSample(self, data_file, data_dir=\"\"):\\n', \"        ''' Return one video read from hdf5 format: \\n\", '        Parameters: \\n', '            data_file: file name (no extention)\\n', '            data_dir: data path\\n', \"        '''\\n\", '        try:\\n', '            # try:\\n', \"            #     f_0 = h5py.File('./sample_data/train/Xm1/X1.h5','r')#This is the first file and will give the first timestamp t0\\n\", '            #     print data_dir\\n', \"            #     print os.path.join(data_dir,'train/Xm1/X1.h5')\\n\", \"            #     # f_0 = h5py.File(os.path.join(data_dir,'train/Xm1/X1.h5'),'r')\\n\", \"            #     t_0 = np.array(f_0['X']['value']['t']['value'][:])[0][0]\\n\", '            # except: # use the first file in /train/Xm1 as starting file\\n', \"            #     f_0 = sorted(os.listdir('./sample_data/train/Xm1/'), key=lambda f:int(f.split('.')[0].split('X')[-1]))[0]\\n\", \"            #     t_0 = np.array(f_0['X']['value']['t']['value'][:])[0][0]\\n\", '            #     vprint (self.verbose, \"Cannot load train/Xm1/X1.h5 to initialize time indexing. Instead use the first file in train/Xm1/.\")\\n', '            \\n', '            t_0 = 1246492800.0\\n', '            \\n', \"            if not data_file.endswith('.h5'):\\n\", \"                data_file = data_file + '.h5'\\n\", \"            f = h5py.File(os.path.join(data_dir, data_file),'r')\\n\", '            try:\\n', \"                X = np.array(f['X']['value']['X']['value'][:])\\n\", '                \\n', '                ### corrected by Lisheng ####\\n', \"                # if 't' in f: \\n\", \"                #     X = np.array(f['t']['value']['t']['value'][:])\\n\", \"                if 't' in f['X']['value']:\\n\", \"                    t_absolute = np.array(f['X']['value']['t']['value'][:])\\n\", '                    # print t_absolute[:,0].tolist()\\n', '                    # print t_0\\n', '                    # t = [int(float(t_abs-t0)/300) for t_abs in t_absolute.tolist()]\\n', '                    t = [(t_abs-t_0)/300 for t_abs in t_absolute[:,0].tolist()]\\n', '                    # print t\\n', '                    t = np.array(t).reshape(t_absolute.shape)\\n', '\\n', '                ### corrected by Lisheng ####\\n', '                else:\\n', '                    t = np.array(range(X.shape[0]))\\n', '                \\n', \"            except: # Lisheng's simpler format\\n\", '                try:\\n', \"                    X = np.array(f['X'][:])\\n\", \"                    if 't' in f: \\n\", \"                        t = np.array(f['t'][:])   \\n\", '                    else:\\n', '                        t = np.array(range(X.shape[0])) \\n', '                except Exception:\\n', '                    vprint(self.verbose, traceback.format_exc())\\n', '                    X = np.array([])\\n', '                    t = np.array([])  \\n', '                \\n', '            if len(t)==0 or len(t)!=len(X):\\n', '                t = np.array(range(X.shape[0])) \\n', '            if len(X.shape) > 3: # turn to gray levels\\n', '                X = X[:,:,:,0]\\n', '            if self.two_d_map:\\n', '                # X_1d = np.hstack((X,t))\\n', '                # print X_1d.shape\\n', \"                # vprint (self.verbose, 'Mapping X to 2D')\\n\", '                X = self.two_d_mapping(X)\\n', '        except Exception:\\n', '            print(traceback.format_exc())\\n', '\\n', '\\n', '        return (X, t)\\n', '        \\n', '    def saveData(self, data_file, data_dir=\"\", frames=[], format=\\'pickle\\', map_to_1d=True, map_to_1d_when_starts_with=\\'Y\\'):\\n', \"        ''' Save data in picke / h5 format.        Parameters: \\n\", '            data_file: save data under this filename (no extention)\\n', '            data_dir: where to save data\\n', '            frames: specify which lines in the video matrix to be saved,  \\n', '            e.g. frames=(start_frame, end_frame)=(10,15)\\n', '                    default = entire video matrix\\n', \"            format: 'pickle' or 'h5', default = 'pickle'\\n\", \"            map_to_1d: bool. True (by default): map the predictions back to 1d when they are saved with a filename starting with the value of parameter 'map_to_1d_when_starts_with'; False: save data as it is.\\n\", '            map_to_1d_when_starts_with: str. Indicates the starting part of filename which will get mapped to 1d when map_to_1d=True\\n', \"        '''\\n\", '        if not data_file.endswith(format):\\n', \"            data_file = data_file + '.' + format\\n\", '        success = True\\n', '        if data_file.startswith(map_to_1d_when_starts_with) and map_to_1d:\\n', '            two_d_map = False\\n', '            self.X = self.map_back_to_1d(self.X)\\n', '        try:\\n', '            filename = os.path.join(data_dir, data_file)\\n', '            vprint(self.verbose, \"Data Manager :: ========= Saving data to \" + filename)\\n', '\\n', '            start = time.time()\\n', '            # Write some code to save the data\\n', '            if frames: \\n', \"                if format=='h5': \\n\", \"                    with h5py.File(filename, 'w') as f:\\n\", \"                        f.create_dataset(name='X', shape=self.X[frames[0]:frames[1]].shape, \\\\\\n\", '                            data=self.X[frames[0]:frames[1]])\\n', \"                        f.create_dataset(name='t', shape=self.t[frames[0]:frames[1]].shape, \\\\\\n\", '                            data=self.t[frames[0]:frames[1]])\\n', '                else: \\n', \"                    with open(filename, 'wb') as f:\\n\", \"                        dict_to_save = {key:self.__dict__[key] for key in self.__dict__.keys() if not key in ['X', 't']}\\n\", \"                        dict_to_save['X'] = self.X[frames[0]:frames[1]]\\n\", \"                        dict_to_save['t'] = self.t[frames[0]:frames[1]]\\n\", '                        pickle.dump(dict_to_save, f, 2)\\n', '            else: #save the entire matrix\\n', \"                if format=='h5':\\n\", \"                    with h5py.File(filename, 'w') as f:\\n\", \"                        f.create_dataset(name='X', shape=self.__dict__['X'].shape, data=self.__dict__['X'])\\n\", \"                        f.create_dataset(name='t', shape=self.__dict__['t'].shape, data=self.__dict__['t'])\\n\", '                else: \\n', \"                    with open(filename, 'wb') as f:\\n\", '                        pickle.dump(self.__dict__, f, 2) \\n', '        except Exception as e: \\n', '            vprint (self.verbose, e)\\n', '            success = False\\n', '        end = time.time()\\n', '        vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '\\n', '\\n', '    def reloadData(self, filename=\"\", data_dir=\"\"):\\n', \"        ''' Reload data in pickle format.'''\\n\", '        success = True\\n', '        vprint(self.verbose, \"Data Manager :: ========= Reloading data from \" + filename)\\n', '        start = time.time()\\n', '        # Write some code to reload the data\\n', '        temp =[]\\n', '        try:\\n', \"            if filename.endswith('h5'): \\n\", \"                with h5py.File(os.path.join(data_dir, filename), 'r') as f:\\n\", \"                    self.X = f['X'][:]\\n\", \"                    self.t = f['t'][:]\\n\", \"            elif filename.endswith('pickle'):\\n\", \"                with open(os.path.join(data_dir, filename), 'rb') as f:\\n\", '                    temp = pickle.load(f)\\n', \"                    self.X = temp['X']\\n\", \"                    self.t = temp['t']\\n\", '                    vprint(self.verbose, filename)\\n', '            else:\\n', '                success = False\\n', '                vprint(self.verbose, \"[-] No such file extension.\" + filename)            \\n', '        except Exception as e: \\n', '            vprint (self.verbose, e)\\n', '            success = False \\n', '        end = time.time()\\n', '        if success:\\n', '            vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '\\n', '    def browse(self):\\n', \"        ''' Open a data browser to browse through the data.'''        \\n\", '\\n', '    def play_video(self):\\n', \"        '''play video in python:\\n\", '        http://stackoverflow.com/questions/21313542/how-to-open-a-mp4-file-with-python\\n', \"        '''\\n\", '\\n', '    def motion_history_image(self, start=0, end=10, step=1, tau=10, d=0):\\n', '        \"\"\"\\n', '        start and end and the first and last frame. step is the stride.\\n', '        tau = 50 means we consider only motions taken within 50 frames.\\n', '        d = difference threshold: \\n', \"        if the difference between 2 images < d at a point (x,y), it's considered a motionless point at t\\n\", '        \"\"\"\\n', '        import matplotlib.pyplot as plt\\n', '        # get video frames \\n', '        nmax = len(self.X)\\n', '        if end>nmax: end=nmax\\n', '        if end<start: end=start\\n', '        frame_index_to_display = range(start, end+1, step)\\n', '        frame_list = self.X[frame_index_to_display]\\n', '        # compute difference images\\n', '        difference_images = np.asarray([frame_list[t+1] - frame_list[t] for t in range(len(frame_list)-1)])\\n', '        tmax,xmax,ymax = difference_images.shape\\n', '        # initialize the motion history image\\n', '        MHI = np.zeros((xmax, ymax))\\n', '        #loop over time\\n', '        for t in range(tmax):        \\n', '            #loop each position\\n', '            for x in range(xmax):\\n', '                for y in range(ymax):\\n', '                    if difference_images[t,x,y] > d: # if moving now\\n', '                        # pixel value = max value = tau\\n', '                        MHI[x,y] = tau \\n', '                    else: # if motionless now\\n', '                        # pixel value decays by 1\\n', '                        MHI[x,y] = max(0, MHI[x,y]-1)         \\n', '        plt.imshow(MHI)\\n', '        plt.colorbar()\\n', '        plt.show()\\n', '        return MHI\\n', '        \\n', '\\n', '    def display(self, start=0, end=0, step=1):\\n', \"        ''' Display frames graphically in a nice way.\\n\", '            start and end and the first and last frame. step is the stride.\\n', \"            self.X is a list of array, each array with shape (32, 32).'''\\n\", '        import matplotlib.pyplot as plt\\n', '        fig = plt.figure()\\n', '        plot_i=1\\n', '        nmax = len(self.X)\\n', '        if end>nmax: end=nmax\\n', '        if end<start: end=start\\n', '        frame_index_to_display = range(start, end+1, step)\\n', '        fnum = len(frame_index_to_display)\\n', '        for i in range(fnum):\\n', '            sf = fig.add_subplot(1, fnum, i+1)\\n', \"            sf.imshow(self.X[frame_index_to_display[i]], cmap='gray', interpolation='None')\\n\", '            plot_i += 1\\n', \"            sf.axis('off')\\n\", '            sf.set_title(str(frame_index_to_display[i]))\\n', '        plt.show()\\n', '\\n', '\\n', '    def two_d_mapping(self, X_1d):\\n', '        \"\"\"\\n', '        map 1-d array to a 2-d space with Self Organizing Maps technique. The map used here is defined by self.map_file\\n', '        \"\"\"\\n', '        try:\\n', '            Midx = np.loadtxt(self.map_file)\\n', '            T = X_1d.shape[0]\\n', '            n = Midx.shape[0] #or[1], Midx is square\\n', '            X_2d = np.empty((T,n,n))\\n', '            for i in range(n):\\n', '                for j in range(n):\\n', '                    X_2d[:,i,j] = X_1d[:, int(Midx[i,j])].reshape((T,))\\n', '            return X_2d\\n', '\\n', '        except Exception:\\n', '            vprint(self.verbose, traceback.format_exc())\\n', '            vprint (self.verbose, \"Error \\\\n Data has not been transformed to 2D array.\") \\n', '            return X_1d\\n', '             # retrain the map\\n', '\\n', '    def map_back_to_1d(self, X_2d):\\n', '        \"\"\"\\n', '        map 2-d array back to 1-d using the same maps for 1-d to 2-d (defined by self.map_file). This is useful when saving predictions\\n', '        for the reason of scoring.\\n', '\\n', '        \"\"\"\\n', '        try:\\n', '            Midx = np.loadtxt(self.map_file)\\n', '            try:\\n', \"                original_Xshape = np.array(h5py.File('./sample_data/train/Xm1/X1.h5','r')['X']['value']['X']['value'][:]).shape\\n\", '            except:\\n', '                vprint (self.verbose, \"Error: Cannot load ./sample_data/train/Xm1/X1.h5.\\\\n Use the default value (1916, 1) for 1d array\") \\n', '                original_Xshape = (12, 1916, 1)\\n', '            # print original_Xshape\\n', '            # print X_2d.shape\\n', '            T, n, _ = X_2d.shape\\n', '            X_1d = np.empty((T, original_Xshape[1], original_Xshape[2]))\\n', '            T,m,_ = X_1d.shape\\n', '            \\n', '            where = 0\\n', '            while where < m:\\n', '                for i in range(n):\\n', '                    for j in range(n):\\n', '                        if int(Midx[i,j]) == where:\\n', '                            X_1d[:, where]=X_2d[:,i,j].reshape(X_1d[:, where].shape)\\n', '                where += 1\\n', '            return X_1d\\n', '            \\n', '\\n', '        except Exception:\\n', '            vprint(self.verbose, traceback.format_exc())\\n', '            vprint (self.verbose, \"Error \\\\n Data has not been transformed back to 1D array.\") \\n', '            return X_2d\\n'], 32)\n",
      "./utilities/data_manager.pyc\n",
      "/Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng\n",
      "************************************************\n",
      "******** Processing data chunk number 1 ********\n",
      "************************************************\n",
      "Data Manager :: Version = 1\n",
      "Data Manager :: Version = 1\n",
      "Version = Persitent\n",
      "Model :: ========= Adapting model =========\n",
      "[+] Success, model adapted in  0.00 sec\n",
      "Model :: ========= Making predictions =========\n",
      "[+] Success, predictions made in  0.00 sec\n",
      "Data Manager :: ========= Saving data to /Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng/results/Y1.h5\n",
      "[+] Success in  0.00 sec\n",
      "[+] Done\n",
      "[+] Time spent  2.48 sec ::  Time budget 600.00 sec\n",
      "\n",
      "====> STEP: 2\n",
      "Using input_dir: ./sample_data\n",
      "Using output_dir: /Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng/results\n",
      "Using code_dir: .\n",
      "Using cache_dir: .\n",
      "{'max_samples': inf, 'verbose': False, 'datatype': 'unknown', 'two_d_map': True, 'use_pickle': False, 'cache_file': '', 'version': '1', 't': array([], dtype=float64), 'X': array([], dtype=float64), 'map_file': './utilities/Midx_199_44by44.txt'}\n",
      "(['class DataManager:\\n', '    \\n', \"    ''' This class aims at loading, saving, and displaying data.\\n\", '    \\n', '    Data members:\\n', '    datatype = one of \"public\", \"feedback\", or \"validate\"\\n', '    X = data matrix, samples in lines (time index increasing with line), features in columns.\\n', '    t = time index. The time index may show ruptures e.g. 0, 1, 2, 3, 0, 1, 2, 3; indicating cuts.\\n', '     \\n', '    Methods defined:\\n', '    __init__ (...)\\n', '        x.__init__([(feature, value)]) -> void\\t\\t\\n', '        Initialize the data members with the tuples (feature, value) given as argument. An unlimited number of tuples can be passed as argument.\\n', '        If input_dir is given, calls loadTrainData.\\n', '        Parameters:\\n', '        two_d_map: bool. Maps 1d array data to 2d using a pre-trained SOM (Self Organizing Map) map when True (default).\\n', \"        map_file: the SOM map used when two_d_map. default ='./utilities/Midx_199_44by44.txt'\\n\", '        \\n', '    loadTrainData (...)\\n', '        x.loadData (input_dir, max_samples=float(\\'inf\\'), verbose=\"True\") -> success\\t\\t\\n', '        Load all the training samples found in directory input_dir/train. \\n', '        Ignores the samples in input_dir/adapt, if any.\\n', '        input_dir/train may contain multiple subdirectories, Xmn/.\\n', '        The data must be read from all of them, it order of DECREASING values of n.\\n', '        The directories contains files Xn.h5, which must be read in order if INCREASING n values.\\n', '        If data are already loaded, this function overwrites X, unless append=\"True\".\\n', '        For speed reasons, stops after max_samples samples (frames) have been read.\\n', '        Returns success=\"True/False\".\\n', '        =============================\\n', '        loadTrainData() returns a ndarray X and a time index array t\\n', '            X.shape(total_num_of_frames=101*125frames/videos, 32,32)\\n', '            t = array([0, ...., 124, 0, ...., 124,...]), t.shape=(total_num_of_frames,)\\n', '\\t\\t\\n', '    appendSamples (...)\\n', '        x.appendSamples (chunk_num, input_dir, verbose=\"True\") -> success\\t\\t\\n', '        Append to X all the samples found in directory input_dir/adapt/Xn.h5, where n=chunk_num.\\n', '        Returns success=\"True/False\".        \\n', '        \\n', '    getInfo (...)\\n', '        x.getInfo () -> string\\t\\n', '        Pretty prints information about the object.\\n', '\\n', '    saveData() \\n', '        save read data (array X, T) to pickle or h5 file\\t\\t\\n', \"    '''\\n\", '\\t\\n', '    def __init__(self, datatype=\"unknown\", data_file=\"\", verbose=False, max_samples=float(\\'inf\\'), cache_file=\"\", two_d_map=True, map_file=\\'./utilities/Midx_199_44by44.txt\\'):\\n', \"        '''Constructor'''\\n\", '        self.version = \"1\"\\n', '        self.datatype = datatype \\n', '        self.verbose = verbose\\n', '        self.max_samples=max_samples\\n', '        self.two_d_map = two_d_map\\n', '        self.map_file = map_file\\n', '        self.cache_file=cache_file # To save/reload data in binary format (only if not empty)\\n', '        if not cache_file: \\n', '            self.use_pickle = False\\n', '        else:\\n', '            self.use_pickle = True\\n', '        self.X = np.array([])\\n', '        self.t = np.array([])\\n', '        vprint(self.verbose, \"Data Manager :: Version = \" + self.version)\\n', '        if data_file:\\n', '            self.loadData(data_file)\\n', '\\n', '           \\n', '    def __repr__(self):\\n', '        return \"DataManager :\\\\n\\\\t\" + str(self.X.__repr__) + \"\\\\n\\\\t\" + str(self.t.__repr__)\\n', '\\n', '    def __str__(self):\\n', '        val = \"DataManager :\\\\n\" + self.getInfo\\n', '        return val\\n', '  \\n', '    def getInfo(self):\\n', \"        '''A nice string with information about the data.'''       \\n\", '        val = \"\"\\n', '        return val\\n', '        \\n', '    def loadTrainData(self, data_dir=\"\", max_samples=float(\\'inf\\')):\\n', \"        ''' Get the data from hdf5 files.'''\\n\", '        success = True\\n', '        data_reloaded = False\\n', '        vprint(self.verbose, \"Data Manager :: ========= Reading training data from \" + data_dir)\\n', '        start = time.time()\\n', '        vid=0\\n', '        if self.use_pickle and self.reloadData(self.cache_file):\\n', '            # Try to reload the file from a pickle\\n', '            data_reloaded = True # Turn \"success\" to false if there is a problem.\\n', '        else:\\n', '            # Load the data into X and t.\\n', '            dir_list = []\\n', '            for dir in os.listdir(data_dir):\\n', '                if os.path.isdir(os.path.join(data_dir, dir)):\\n', '                    dir_list.append(dir)\\n', '            # sort dir in decreasing order of n for n in Xmn        \\n', \"            dir_list = sorted(dir_list, key=lambda i: i.split('m')[-1], reverse=True)\\n\", '            vprint(self.verbose, dir_list)\\n', '            self.X=np.array([]) # Re-initialize from scratch\\n', '            self.t=np.array([])\\n', '            for dir in dir_list:\\n', \"                for data_file in sorted([h5file for h5file in os.listdir(os.path.join(data_dir, dir)) if h5file.endswith('h5')],key=lambda i:int(i.split('.')[0].split('X')[-1])):\\n\", '                    vprint(self.verbose, \"Loading %s\"%data_file)\\n', '                    self.appendSamples(data_file, os.path.join(data_dir, dir), verbose=False)\\n', '                    vid=vid+1\\n', '                   \\n', '        if self.use_pickle and not data_reloaded:\\n', '            # Save data as a pickle for \"faster\" later reload\\n', \"            self.saveData(self.cache_file, format='pickle')\\n\", '            \\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose, \"[+] Success, loaded %d videos in %5.2f sec\" % (vid, end - start))\\n', '        return success\\n', '\\t\\n', '\\n', '    def appendSamples(self, data_file, data_dir=\"\", verbose=False):\\n', \"        ''' After loading training samples, get additional data from the adapt directory.\\n\", \"        data_file: Number n of the 'chunk' or 'step' (appearing in the file name)\\n\", '        Alternatively, the full file name Xn can be supplied as a string instead of the chunk number.\\n', \"        '''\\n\", '        success = True\\n', '        start = time.time()\\n', '        # Append new data to X and t.\\n', '        if isinstance(data_file, int):\\n', '            data_file = \"X\" + str(data_file)\\n', '        vprint(self.verbose and verbose, \"Data Manager :: ========= Appending samples \" + data_dir +  data_file)\\n', '        X_add, t_add = self.getOneSample(data_file, data_dir)\\n', '        #if t_add[0]==0: print \"New sequence\"\\n', '        #print \"%s %d %d %d\" % (data_file, np.min(t_add), np.max(t_add), len(t_add))\\n', '            \\n', '        if len(self.X)==0:\\n', '            self.X = X_add\\n', '            self.t = t_add\\n', '        else:\\n', '            self.X = np.vstack((self.X, X_add))\\n', '\\n', '            if t_add[0][0] == 0:\\n', '                t_add = np.array([t+1+self.t[-1][0] for t in t_add]).reshape(t_add.shape)\\n', '            self.t = np.vstack((self.t, t_add))\\n', '\\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose and verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose and verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '        \\n', '    def loadData(self, data_file, data_dir=\"\"):\\n', \"        ''' Erase previous data and load data from a give data file.\\n\", \"        data_file: Number n of the 'chunk' or 'step' (appearing in the file name)\\n\", '        Alternatively, the full file name Xn can be supplied as a string instead of the chunk number.\\n', \"        '''\\n\", '        success = True\\n', '        start = time.time() \\n', '        if isinstance(data_file, int):\\n', '            data_file = \"X\" + str(data_file)\\n', '        vprint(self.verbose, \"Data Manager :: ========= Loading data from \" + data_file)          \\n', '        self.X, self.t = self.getOneSample(data_file, data_dir)\\n', '        end = time.time()\\n', '        if len(self.X)==0:\\n', '            success = False \\n', '            vprint(self.verbose, \"[-] Loading failed\")\\n', '        else:\\n', '            vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        \\n', '        return success\\n', '        \\n', '    def getOneSample(self, data_file, data_dir=\"\"):\\n', \"        ''' Return one video read from hdf5 format: \\n\", '        Parameters: \\n', '            data_file: file name (no extention)\\n', '            data_dir: data path\\n', \"        '''\\n\", '        try:\\n', '            # try:\\n', \"            #     f_0 = h5py.File('./sample_data/train/Xm1/X1.h5','r')#This is the first file and will give the first timestamp t0\\n\", '            #     print data_dir\\n', \"            #     print os.path.join(data_dir,'train/Xm1/X1.h5')\\n\", \"            #     # f_0 = h5py.File(os.path.join(data_dir,'train/Xm1/X1.h5'),'r')\\n\", \"            #     t_0 = np.array(f_0['X']['value']['t']['value'][:])[0][0]\\n\", '            # except: # use the first file in /train/Xm1 as starting file\\n', \"            #     f_0 = sorted(os.listdir('./sample_data/train/Xm1/'), key=lambda f:int(f.split('.')[0].split('X')[-1]))[0]\\n\", \"            #     t_0 = np.array(f_0['X']['value']['t']['value'][:])[0][0]\\n\", '            #     vprint (self.verbose, \"Cannot load train/Xm1/X1.h5 to initialize time indexing. Instead use the first file in train/Xm1/.\")\\n', '            \\n', '            t_0 = 1246492800.0\\n', '            \\n', \"            if not data_file.endswith('.h5'):\\n\", \"                data_file = data_file + '.h5'\\n\", \"            f = h5py.File(os.path.join(data_dir, data_file),'r')\\n\", '            try:\\n', \"                X = np.array(f['X']['value']['X']['value'][:])\\n\", '                \\n', '                ### corrected by Lisheng ####\\n', \"                # if 't' in f: \\n\", \"                #     X = np.array(f['t']['value']['t']['value'][:])\\n\", \"                if 't' in f['X']['value']:\\n\", \"                    t_absolute = np.array(f['X']['value']['t']['value'][:])\\n\", '                    # print t_absolute[:,0].tolist()\\n', '                    # print t_0\\n', '                    # t = [int(float(t_abs-t0)/300) for t_abs in t_absolute.tolist()]\\n', '                    t = [(t_abs-t_0)/300 for t_abs in t_absolute[:,0].tolist()]\\n', '                    # print t\\n', '                    t = np.array(t).reshape(t_absolute.shape)\\n', '\\n', '                ### corrected by Lisheng ####\\n', '                else:\\n', '                    t = np.array(range(X.shape[0]))\\n', '                \\n', \"            except: # Lisheng's simpler format\\n\", '                try:\\n', \"                    X = np.array(f['X'][:])\\n\", \"                    if 't' in f: \\n\", \"                        t = np.array(f['t'][:])   \\n\", '                    else:\\n', '                        t = np.array(range(X.shape[0])) \\n', '                except Exception:\\n', '                    vprint(self.verbose, traceback.format_exc())\\n', '                    X = np.array([])\\n', '                    t = np.array([])  \\n', '                \\n', '            if len(t)==0 or len(t)!=len(X):\\n', '                t = np.array(range(X.shape[0])) \\n', '            if len(X.shape) > 3: # turn to gray levels\\n', '                X = X[:,:,:,0]\\n', '            if self.two_d_map:\\n', '                # X_1d = np.hstack((X,t))\\n', '                # print X_1d.shape\\n', \"                # vprint (self.verbose, 'Mapping X to 2D')\\n\", '                X = self.two_d_mapping(X)\\n', '        except Exception:\\n', '            print(traceback.format_exc())\\n', '\\n', '\\n', '        return (X, t)\\n', '        \\n', '    def saveData(self, data_file, data_dir=\"\", frames=[], format=\\'pickle\\', map_to_1d=True, map_to_1d_when_starts_with=\\'Y\\'):\\n', \"        ''' Save data in picke / h5 format.        Parameters: \\n\", '            data_file: save data under this filename (no extention)\\n', '            data_dir: where to save data\\n', '            frames: specify which lines in the video matrix to be saved,  \\n', '            e.g. frames=(start_frame, end_frame)=(10,15)\\n', '                    default = entire video matrix\\n', \"            format: 'pickle' or 'h5', default = 'pickle'\\n\", \"            map_to_1d: bool. True (by default): map the predictions back to 1d when they are saved with a filename starting with the value of parameter 'map_to_1d_when_starts_with'; False: save data as it is.\\n\", '            map_to_1d_when_starts_with: str. Indicates the starting part of filename which will get mapped to 1d when map_to_1d=True\\n', \"        '''\\n\", '        if not data_file.endswith(format):\\n', \"            data_file = data_file + '.' + format\\n\", '        success = True\\n', '        if data_file.startswith(map_to_1d_when_starts_with) and map_to_1d:\\n', '            two_d_map = False\\n', '            self.X = self.map_back_to_1d(self.X)\\n', '        try:\\n', '            filename = os.path.join(data_dir, data_file)\\n', '            vprint(self.verbose, \"Data Manager :: ========= Saving data to \" + filename)\\n', '\\n', '            start = time.time()\\n', '            # Write some code to save the data\\n', '            if frames: \\n', \"                if format=='h5': \\n\", \"                    with h5py.File(filename, 'w') as f:\\n\", \"                        f.create_dataset(name='X', shape=self.X[frames[0]:frames[1]].shape, \\\\\\n\", '                            data=self.X[frames[0]:frames[1]])\\n', \"                        f.create_dataset(name='t', shape=self.t[frames[0]:frames[1]].shape, \\\\\\n\", '                            data=self.t[frames[0]:frames[1]])\\n', '                else: \\n', \"                    with open(filename, 'wb') as f:\\n\", \"                        dict_to_save = {key:self.__dict__[key] for key in self.__dict__.keys() if not key in ['X', 't']}\\n\", \"                        dict_to_save['X'] = self.X[frames[0]:frames[1]]\\n\", \"                        dict_to_save['t'] = self.t[frames[0]:frames[1]]\\n\", '                        pickle.dump(dict_to_save, f, 2)\\n', '            else: #save the entire matrix\\n', \"                if format=='h5':\\n\", \"                    with h5py.File(filename, 'w') as f:\\n\", \"                        f.create_dataset(name='X', shape=self.__dict__['X'].shape, data=self.__dict__['X'])\\n\", \"                        f.create_dataset(name='t', shape=self.__dict__['t'].shape, data=self.__dict__['t'])\\n\", '                else: \\n', \"                    with open(filename, 'wb') as f:\\n\", '                        pickle.dump(self.__dict__, f, 2) \\n', '        except Exception as e: \\n', '            vprint (self.verbose, e)\\n', '            success = False\\n', '        end = time.time()\\n', '        vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '\\n', '\\n', '    def reloadData(self, filename=\"\", data_dir=\"\"):\\n', \"        ''' Reload data in pickle format.'''\\n\", '        success = True\\n', '        vprint(self.verbose, \"Data Manager :: ========= Reloading data from \" + filename)\\n', '        start = time.time()\\n', '        # Write some code to reload the data\\n', '        temp =[]\\n', '        try:\\n', \"            if filename.endswith('h5'): \\n\", \"                with h5py.File(os.path.join(data_dir, filename), 'r') as f:\\n\", \"                    self.X = f['X'][:]\\n\", \"                    self.t = f['t'][:]\\n\", \"            elif filename.endswith('pickle'):\\n\", \"                with open(os.path.join(data_dir, filename), 'rb') as f:\\n\", '                    temp = pickle.load(f)\\n', \"                    self.X = temp['X']\\n\", \"                    self.t = temp['t']\\n\", '                    vprint(self.verbose, filename)\\n', '            else:\\n', '                success = False\\n', '                vprint(self.verbose, \"[-] No such file extension.\" + filename)            \\n', '        except Exception as e: \\n', '            vprint (self.verbose, e)\\n', '            success = False \\n', '        end = time.time()\\n', '        if success:\\n', '            vprint(self.verbose, \"[+] Success in %5.2f sec\" % (end - start))\\n', '        return success\\n', '\\n', '    def browse(self):\\n', \"        ''' Open a data browser to browse through the data.'''        \\n\", '\\n', '    def play_video(self):\\n', \"        '''play video in python:\\n\", '        http://stackoverflow.com/questions/21313542/how-to-open-a-mp4-file-with-python\\n', \"        '''\\n\", '\\n', '    def motion_history_image(self, start=0, end=10, step=1, tau=10, d=0):\\n', '        \"\"\"\\n', '        start and end and the first and last frame. step is the stride.\\n', '        tau = 50 means we consider only motions taken within 50 frames.\\n', '        d = difference threshold: \\n', \"        if the difference between 2 images < d at a point (x,y), it's considered a motionless point at t\\n\", '        \"\"\"\\n', '        import matplotlib.pyplot as plt\\n', '        # get video frames \\n', '        nmax = len(self.X)\\n', '        if end>nmax: end=nmax\\n', '        if end<start: end=start\\n', '        frame_index_to_display = range(start, end+1, step)\\n', '        frame_list = self.X[frame_index_to_display]\\n', '        # compute difference images\\n', '        difference_images = np.asarray([frame_list[t+1] - frame_list[t] for t in range(len(frame_list)-1)])\\n', '        tmax,xmax,ymax = difference_images.shape\\n', '        # initialize the motion history image\\n', '        MHI = np.zeros((xmax, ymax))\\n', '        #loop over time\\n', '        for t in range(tmax):        \\n', '            #loop each position\\n', '            for x in range(xmax):\\n', '                for y in range(ymax):\\n', '                    if difference_images[t,x,y] > d: # if moving now\\n', '                        # pixel value = max value = tau\\n', '                        MHI[x,y] = tau \\n', '                    else: # if motionless now\\n', '                        # pixel value decays by 1\\n', '                        MHI[x,y] = max(0, MHI[x,y]-1)         \\n', '        plt.imshow(MHI)\\n', '        plt.colorbar()\\n', '        plt.show()\\n', '        return MHI\\n', '        \\n', '\\n', '    def display(self, start=0, end=0, step=1):\\n', \"        ''' Display frames graphically in a nice way.\\n\", '            start and end and the first and last frame. step is the stride.\\n', \"            self.X is a list of array, each array with shape (32, 32).'''\\n\", '        import matplotlib.pyplot as plt\\n', '        fig = plt.figure()\\n', '        plot_i=1\\n', '        nmax = len(self.X)\\n', '        if end>nmax: end=nmax\\n', '        if end<start: end=start\\n', '        frame_index_to_display = range(start, end+1, step)\\n', '        fnum = len(frame_index_to_display)\\n', '        for i in range(fnum):\\n', '            sf = fig.add_subplot(1, fnum, i+1)\\n', \"            sf.imshow(self.X[frame_index_to_display[i]], cmap='gray', interpolation='None')\\n\", '            plot_i += 1\\n', \"            sf.axis('off')\\n\", '            sf.set_title(str(frame_index_to_display[i]))\\n', '        plt.show()\\n', '\\n', '\\n', '    def two_d_mapping(self, X_1d):\\n', '        \"\"\"\\n', '        map 1-d array to a 2-d space with Self Organizing Maps technique. The map used here is defined by self.map_file\\n', '        \"\"\"\\n', '        try:\\n', '            Midx = np.loadtxt(self.map_file)\\n', '            T = X_1d.shape[0]\\n', '            n = Midx.shape[0] #or[1], Midx is square\\n', '            X_2d = np.empty((T,n,n))\\n', '            for i in range(n):\\n', '                for j in range(n):\\n', '                    X_2d[:,i,j] = X_1d[:, int(Midx[i,j])].reshape((T,))\\n', '            return X_2d\\n', '\\n', '        except Exception:\\n', '            vprint(self.verbose, traceback.format_exc())\\n', '            vprint (self.verbose, \"Error \\\\n Data has not been transformed to 2D array.\") \\n', '            return X_1d\\n', '             # retrain the map\\n', '\\n', '    def map_back_to_1d(self, X_2d):\\n', '        \"\"\"\\n', '        map 2-d array back to 1-d using the same maps for 1-d to 2-d (defined by self.map_file). This is useful when saving predictions\\n', '        for the reason of scoring.\\n', '\\n', '        \"\"\"\\n', '        try:\\n', '            Midx = np.loadtxt(self.map_file)\\n', '            try:\\n', \"                original_Xshape = np.array(h5py.File('./sample_data/train/Xm1/X1.h5','r')['X']['value']['X']['value'][:]).shape\\n\", '            except:\\n', '                vprint (self.verbose, \"Error: Cannot load ./sample_data/train/Xm1/X1.h5.\\\\n Use the default value (1916, 1) for 1d array\") \\n', '                original_Xshape = (12, 1916, 1)\\n', '            # print original_Xshape\\n', '            # print X_2d.shape\\n', '            T, n, _ = X_2d.shape\\n', '            X_1d = np.empty((T, original_Xshape[1], original_Xshape[2]))\\n', '            T,m,_ = X_1d.shape\\n', '            \\n', '            where = 0\\n', '            while where < m:\\n', '                for i in range(n):\\n', '                    for j in range(n):\\n', '                        if int(Midx[i,j]) == where:\\n', '                            X_1d[:, where]=X_2d[:,i,j].reshape(X_1d[:, where].shape)\\n', '                where += 1\\n', '            return X_1d\\n', '            \\n', '\\n', '        except Exception:\\n', '            vprint(self.verbose, traceback.format_exc())\\n', '            vprint (self.verbose, \"Error \\\\n Data has not been transformed back to 1D array.\") \\n', '            return X_2d\\n'], 32)\n",
      "./utilities/data_manager.pyc\n",
      "/Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng\n",
      "************************************************\n",
      "******** Processing data chunk number 2 ********\n",
      "************************************************\n",
      "Data Manager :: Version = 1\n",
      "Data Manager :: Version = 1\n",
      "Version = Persitent\n",
      "Model :: ========= Adapting model =========\n",
      "[+] Success, model adapted in  0.00 sec\n",
      "Model :: ========= Making predictions =========\n",
      "[+] Success, predictions made in  0.00 sec\n",
      "Data Manager :: ========= Saving data to /Users/lishengsun/Downloads/zSee4C_starting_kit_Lisheng/results/Y2.h5\n",
      "[+] Success in  0.00 sec\n",
      "[+] Done\n",
      "[+] Time spent  2.32 sec ::  Time budget 600.00 sec\n"
     ]
    }
   ],
   "source": [
    "max_steps = 3 # Change this to the number of steps you want to test\n",
    "for n in range(max_steps):\n",
    "    step_num = str(n)\n",
    "    !python predictSpatioTemporal.py $step_num $data_dir $out_dir $root_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making your Submission\n",
    "\n",
    "Zip your code, including the <span style=\"color:red\">sample_code/</span> directory, and the two scripts <span style=\"color:red\">predictSpatioTemporal.py</span> and <span style=\"color:red\">predict.sh</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit the file: ../sample_submission_17-06-23-23-34.zip\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from data_io import zip_submission\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "submission_filename = '../sample_submission_' + the_date + '.zip'\n",
    "zip_submission(submission_filename, root_dir)\n",
    "print(\"Submit the file: \" + submission_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
